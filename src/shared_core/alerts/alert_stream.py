"""Alert publishing and storage helpers."""

from __future__ import annotations

import json
import logging
import random
import string
import time
from datetime import datetime
from typing import Any, Dict, List, Optional

from shared_core.redis_clients.redis_client import get_redis_client
from shared_core.redis_clients.redis_key_standards import (
    DatabaseAwareKeyBuilder,
    RedisKeyStandards,
)
from shared_core.redis_clients.unified_data_storage import get_unified_storage

try:  # Optional fast serializer
    import orjson

    ORJSON_AVAILABLE = True
except Exception:  # pragma: no cover - optional dependency
    ORJSON_AVAILABLE = False
    orjson = None


class AlertPublisher:
    """Publishes alerts to Redis streams only."""

    def __init__(
        self,
        *,
        redis_client=None,
        pattern_registry: Optional[Dict[str, Any]] = None,
        max_alert_age_seconds: int = 300,
    ) -> None:
        self.logger = logging.getLogger(__name__)
        self.redis = redis_client or get_redis_client(process_name="alert_publisher", db=1)
        self.pattern_registry = pattern_registry or {}
        self.max_alert_age_seconds = max_alert_age_seconds

    def get_pattern_config(self, pattern_type: str) -> Optional[Dict[str, Any]]:
        configs = self.pattern_registry.get("pattern_configs", {})
        return configs.get(pattern_type)

    def _generate_alert_id(self, symbol: str) -> str:
        timestamp_ns = int(time.time() * 1e9)
        random_suffix = "".join(random.choices(string.ascii_lowercase + string.digits, k=6))
        return f"{symbol}_{timestamp_ns}_{random_suffix}"

    def _prepare_payload(self, symbol: str, pattern_data: Dict[str, Any]) -> Dict[str, Any]:
        canonical_symbol = RedisKeyStandards.canonical_symbol(symbol or "UNKNOWN")
        timestamp_ms = int(time.time() * 1000)
        pattern_type = pattern_data.get("pattern_type", "unknown")
        config = self.get_pattern_config(pattern_type) or {}

        payload = {
            "alert_id": pattern_data.get("alert_id") or self._generate_alert_id(canonical_symbol),
            "symbol": canonical_symbol,
            "pattern_type": pattern_type,
            "pattern_name": pattern_data.get("pattern_name", "unknown"),
            "confidence": float(pattern_data.get("confidence", 0.0)),
            "current_price": float(pattern_data.get("current_price", pattern_data.get("last_price", 0.0))),
            "timestamp": timestamp_ms,
            "signal": pattern_data.get("signal", "NEUTRAL"),
            "direction": pattern_data.get("direction", "NEUTRAL"),
            "created_at": datetime.now().isoformat(),
        }

        if config:
            payload.update(
                {
                    "pattern_category": config.get("category"),
                    "pattern_enabled": config.get("enabled", True),
                    "mathematical_integrity": config.get("mathematical_integrity", False),
                    "risk_manager_integration": config.get("risk_manager_integration", False),
                    "emergency_filter_tier": config.get("emergency_filter_tier"),
                    "emergency_filter_group_size": config.get("emergency_filter_group_size"),
                    "pattern_description": config.get("description", ""),
                }
            )

        # include any extra attributes already present
        for key, value in pattern_data.items():
            if key not in payload:
                payload[key] = value

        return payload

    def _serialize(self, payload: Dict[str, Any]) -> bytes:
        if ORJSON_AVAILABLE:
            return orjson.dumps(payload, option=orjson.OPT_SERIALIZE_NUMPY)  # type: ignore[arg-type]
        return json.dumps(payload, default=str).encode("utf-8")

    def publish_alert(self, alert: Dict[str, Any], stream: str = "alerts:stream") -> Optional[str]:
        """Publish a single alert to the configured stream."""

        if not self.redis:
            self.logger.error("AlertPublisher redis client is not available")
            return None

        algo_alert = alert.get("algo_alert")
        if not isinstance(algo_alert, dict):
            raise ValueError("Alert payload must include 'algo_alert' generated by unified_alert_builder")

        alert_timestamp = algo_alert.get("timestamp")
        if isinstance(alert_timestamp, (int, float)):
            alert_age = time.time() - float(alert_timestamp)
        else:
            alert_age = 0

        if alert_age > self.max_alert_age_seconds:
            self.logger.warning("Discarding stale alert %s (age=%ss)", algo_alert.get("alert_id"), int(alert_age))
            return None

        payload = algo_alert.copy()
        payload.setdefault("stream_timestamp", datetime.now().isoformat())
        payload.setdefault("stream_source", "alert_publisher")

        serialized = self._serialize(payload)
        message_id = self.redis.xadd(stream, {b"data": serialized}, maxlen=1000, approximate=True)
        self.logger.debug("Published alert %s to stream %s", payload.get("alert_id"), stream)
        return message_id

    def publish_batch_alerts(self, alerts: List[Dict[str, Any]]) -> bool:
        """Publish multiple alerts using a pipeline."""

        if not alerts:
            return True
        if not self.redis:
            self.logger.error("AlertPublisher redis client is not available")
            return False

        from shared_core.redis_clients.redis_key_standards import DatabaseAwareKeyBuilder

        alerts_stream_key = DatabaseAwareKeyBuilder.live_alerts_stream()
        alerts_telegram_key = DatabaseAwareKeyBuilder.live_alerts_telegram()

        pipeline = self.redis.pipeline()
        for alert in alerts:
            payload = self._prepare_payload(alert.get("symbol", "UNKNOWN"), alert)
            serialized = self._serialize(payload)
            pipeline.xadd(alerts_stream_key, {b"data": serialized}, maxlen=10000, approximate=True)
            pipeline.xadd(alerts_telegram_key, {b"data": serialized}, maxlen=5000, approximate=True)

        try:
            pipeline.execute()
            self.logger.info("Published %s alerts to streams", len(alerts))
            return True
        except Exception as exc:
            self.logger.error("Failed to publish alert batch: %s", exc)
            return False


class AlertStorage:
    """Stores alerts and validation results in DB 2."""

    def __init__(self, *, redis_client=None) -> None:
        self.logger = logging.getLogger(__name__)
        self.storage = get_unified_storage(redis_client=redis_client, db=2)
        self.redis = getattr(self.storage, "redis", None) or getattr(self.storage, "redis_client", None)
        if self.redis is None and hasattr(self.storage, "_get_client"):
            self.redis = self.storage._get_client()

    def store_alert(self, alert_payload: Dict[str, Any]) -> bool:
        if not self.redis:
            self.logger.warning("AlertStorage redis client is not available")
            return False

        alert_id = alert_payload.get("alert_id")
        if not alert_id:
            self.logger.warning("Cannot store alert without alert_id")
            return False

        alert_data = alert_payload.copy()
        alert_data["storage_db"] = 2
        alert_data["stored_at"] = datetime.now().isoformat()

        key = DatabaseAwareKeyBuilder.analytics_alert_storage(alert_id)
        try:
            self.redis.set(key, json.dumps(alert_data), ex=604800)  # 7 days
            self.logger.debug("Stored alert metadata for %s", alert_id)
            return True
        except Exception as exc:
            self.logger.error("Failed to store alert metadata for %s: %s", alert_id, exc)
            return False

    def store_alert_batch(self, alert_payloads: List[Dict[str, Any]]) -> bool:
        if not alert_payloads:
            return True
        if not self.redis:
            self.logger.warning("AlertStorage redis client is not available")
            return False

        pipeline = self.redis.pipeline()
        for payload in alert_payloads:
            alert_id = payload.get("alert_id")
            if not alert_id:
                continue
            alert_data = payload.copy()
            alert_data["storage_db"] = 2
            alert_data["stored_at"] = datetime.now().isoformat()
            key = DatabaseAwareKeyBuilder.analytics_alert_storage(alert_id)
            pipeline.set(key, json.dumps(alert_data), ex=604800)

        try:
            pipeline.execute()
            self.logger.info("Stored %s alerts in DB2", len(alert_payloads))
            return True
        except Exception as exc:
            self.logger.error("Failed to batch store alerts: %s", exc)
            return False

    def store_validation_result(self, alert_id: str, validation_data: Dict[str, Any]) -> bool:
        """
        Store pattern validation result with hashes, streams, and recent list.
        """
        if not self.redis:
            self.logger.warning("AlertStorage redis client is not available")
            return False

        try:
            validation_data = validation_data.copy()
            validation_data["stored_at"] = datetime.now().isoformat()
            validation_data["storage_db"] = 2
            validation_data["alert_id"] = alert_id

            hash_key = DatabaseAwareKeyBuilder.analytics_validation_storage(alert_id)
            self.redis.hset(
                hash_key,
                mapping={
                    "alert_id": alert_id,
                    "data": json.dumps(validation_data),
                    "stored_at": validation_data["stored_at"],
                },
            )

            stream_key = DatabaseAwareKeyBuilder.analytics_validation_stream()
            stream_payload = {
                field: (json.dumps(value) if isinstance(value, (dict, list)) else str(value))
                for field, value in validation_data.items()
            }
            self.redis.xadd(stream_key, stream_payload, maxlen=1000, approximate=True)

            recent_key = DatabaseAwareKeyBuilder.analytics_validation_recent()
            self.redis.lpush(recent_key, json.dumps(validation_data))
            self.redis.ltrim(recent_key, 0, 99)
            self.logger.debug("Stored validation result for %s", alert_id)
            return True
        except Exception as exc:
            self.logger.error("Failed to store validation result for %s: %s", alert_id, exc)
            return False
