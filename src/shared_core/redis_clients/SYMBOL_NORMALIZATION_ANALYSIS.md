# Symbol Normalization Analysis - Duplicate Normalization Issues

**Date:** 2025-01-XX  
**Purpose:** Identify where symbols are normalized and find duplicate normalization that overrides central logic

---

## Executive Summary

**CRITICAL FINDING:** The websocket parser stores tick data with **RAW symbols** (not normalized), while downstream consumers (data_pipeline) **re-normalize** symbols, creating inconsistency and potential data lookup failures.

---

## 1. Websocket Parser - Symbol Storage (Source of Truth)

### Location
`zerodha/crawlers/intraday_websocket_parser.py`

### Storage Method
```python
def _store_tick_data(self, tick: Dict[str, Any]):
    """Store tick data in Redis using unified standards"""
    symbol = tick.get('symbol')  # ‚ö†Ô∏è RAW symbol (not normalized)
    
    # Normalize tick data (field names only, NOT symbols)
    normalized = normalize_redis_tick_data(tick)  # Only normalizes field names
    
    # Store tick with RAW symbol
    key = self.key_builder.live_ticks_latest(symbol)  # ‚ö†Ô∏è Uses raw symbol
    self.redis_client.hset(key, mapping=normalized)
    
    # Store indicators with RAW symbol
    self.storage.store_indicators(symbol, indicators)  # ‚ö†Ô∏è Uses raw symbol
```

### Key Findings
- **Line 1131:** `symbol = tick.get('symbol')` - Gets symbol from tick (may be raw or normalized)
- **Line 1136:** `normalize_redis_tick_data(tick)` - Normalizes **field names**, NOT symbols
- **Line 1139:** `self.key_builder.live_ticks_latest(symbol)` - ‚úÖ **KEY BUILDER NORMALIZES INTERNALLY**
- **Line 1146:** `self.storage.store_indicators(symbol, indicators)` - ‚úÖ **STORAGE NORMALIZES INTERNALLY**

### Key Builder Normalization (CONFIRMED)
**The key builder methods normalize symbols internally:**
```python
@staticmethod
def live_ticks_latest(symbol: str) -> str:
    """Latest tick hash storage - DB1 (ticks:latest:{symbol})"""
    canonical_sym = RedisKeyStandards.canonical_symbol(symbol)  # ‚úÖ NORMALIZES
    return f"ticks:latest:{canonical_sym}"
```

**So the websocket parser DOES normalize symbols via the key builder**, even if it passes a raw symbol.

### Potential Issue
**The symbol IN THE TICK DATA itself might still be raw**, even though the Redis key is normalized. This could cause issues if downstream consumers expect the symbol field in tick data to match the normalized key format.

---

## 2. Data Pipeline - Symbol Normalization (Downstream Consumer)

### Location
`intraday_scanner/data_pipeline.py`

### Normalization Method
```python
def _get_unified_symbol(self, tick_data: dict) -> str:
    """‚úÖ UNIFIED: Single source of truth for symbol extraction and normalization."""
    raw_symbol = tick_data.get("tradingsymbol") or tick_data.get("symbol")
    
    # Step 3: ‚úÖ CRITICAL FIX: Use UniversalSymbolParser.parse_symbol()
    parser = get_symbol_parser()
    parsed = parser.parse_symbol(symbol_str)
    
    # Get canonical symbol
    canonical_symbol = RedisKeyStandards.canonical_symbol(symbol_str)  # ‚úÖ NORMALIZES
    
    if canonical_symbol and canonical_symbol != symbol_str:
        symbol_str = canonical_symbol  # ‚úÖ Uses normalized symbol
    
    # Step 4: Update tick_data for downstream consistency
    tick_data['symbol'] = symbol_str  # ‚úÖ Updates tick_data with normalized symbol
    tick_data['tradingsymbol'] = symbol_str
    
    return symbol_str
```

### Usage in Processing
```python
def _process_tick_for_patterns(self, tick_data):
    # ‚úÖ FIXED: Use unified symbol extraction method
    symbol = self._get_unified_symbol(tick_data) or "UNKNOWN"  # ‚úÖ NORMALIZES
    
    # Ensure symbol is present in indicators downstream (use normalized symbol)
    if "symbol" not in tick_data and symbol:
        tick_data["symbol"] = symbol  # ‚úÖ Updates with normalized symbol
    elif symbol and tick_data.get("symbol") != symbol:
        tick_data["symbol"] = symbol  # ‚úÖ Overrides with normalized symbol
        tick_data["tradingsymbol"] = symbol
```

### Key Findings
- **Line 914-1011:** `_get_unified_symbol()` method **normalizes symbols** using `RedisKeyStandards.canonical_symbol()`
- **Line 3250:** `symbol = self._get_unified_symbol(tick_data)` - **Re-normalizes** symbols when processing
- **Line 3256:** Updates `tick_data["symbol"]` with normalized symbol

### Issue
**Data pipeline RE-normalizes symbols that were already stored with raw symbols**, creating a mismatch between:
- What's stored in Redis (raw symbol format)
- What's expected when reading (canonical symbol format)

---

## 3. Key Builder Methods - Internal Normalization

### Question
Do key builder methods like `live_ticks_latest()` normalize symbols internally?

### Analysis Needed
According to CENTRALIZED_SYSTEMS.md:
- **For OHLC keys:** Key builder methods normalize internally using `normalize_symbol()`
- **For ticks/indicators/greeks keys:** Key builder methods normalize internally using `canonical_symbol()`

**However**, the websocket parser is passing RAW symbols to these methods, so even if they normalize internally, the stored data still has the raw symbol in the tick data itself.

---

## 4. Potential Issue: Symbol in Tick Data vs Redis Key

### Storage Format (Websocket Parser)
```
Redis Key: ticks:latest:NFONIFTY25NOV26400CE  (‚úÖ normalized by key builder)
Tick Data: {
    "symbol": "NIFTY25NOV26400CE",  (‚ö†Ô∏è might still be raw)
    "last_price": 19500.0,
    ...
}
```

### Expected Format (Data Pipeline)
```
Redis Key: ticks:latest:NFONIFTY25NOV26400CE  (‚úÖ normalized)
Tick Data: {
    "symbol": "NFONIFTY25NOV26400CE",  (‚úÖ normalized by data_pipeline)
    "last_price": 19500.0,
    ...
}
```

### Result
- **Redis keys are normalized** (via key builder) ‚úÖ
- **Symbol in tick data might be raw** (not normalized in tick data itself) ‚ö†Ô∏è
- **Data pipeline re-normalizes** the symbol field when processing
- **Potential issue:** Symbol field in stored tick data doesn't match the normalized key format

---

## 5. Data Pipeline Preservation (‚úÖ Already Implemented)

### Comprehensive Field Preservation

The `data_pipeline._clean_tick_data_core_enhanced()` method ensures **ALL computed data is preserved**:

#### Step 1: Preserve ALL Original Data
```python
def _preserve_all_original_data(self, tick_data: dict, cleaned: dict):
    """Preserve EVERY field from original tick data including all indicators, Greeks, volume_ratio, price_change."""
    for key, value in tick_data.items():
        if key in ['_id', '__class__']:
            continue
        cleaned[key] = value  # ‚úÖ Preserves EVERYTHING
```

#### Step 2: Smart Merge from Redis
```python
def _smart_merge_redis_data(self, cleaned: dict, redis_data: dict, original_tick: dict):
    """Merge Redis data to fill gaps without overwriting fresh tick data."""
    
    critical_fields = [
        # Volume and Price
        'volume_ratio', 'price_change', 'price_change_pct', 'normalized_volume', 'volume_spike', 'volume_trend',
        
        # Classical Greeks
        'delta', 'gamma', 'theta', 'vega', 'rho', 'iv', 'implied_volatility',
        
        # Advanced Greeks (ALL 6 higher-order Greeks)
        'vanna', 'charm', 'vomma', 'speed', 'zomma', 'color',
        
        # Option Metadata
        'dte_years', 'trading_dte', 'expiry_series', 'option_price', 'underlying_price', 'strike_price',
        'spot_price', 'moneyness', 'intrinsic_value', 'time_value',
        
        # Gamma Exposure and Advanced Option Metrics
        'gamma_exposure', 'gamma_risk', 'delta_risk', 'theta_decay', 'vega_sensitivity', 'rho_sensitivity',
        
        # Technical Indicators
        'rsi', 'macd', 'sma_20', 'ema_5', 'ema_10', 'ema_20', 'ema_50', 'ema_100', 'ema_200',
        'atr', 'vwap', 'bollinger_bands', 'z_score', 'iv_baseline', 'price_move', 'price_movement',
        
        # Microstructure Indicators (ALL 11 indicators)
        'microprice', 'order_flow_imbalance', 'order_book_imbalance',
        'cumulative_volume_delta', 'spread_absolute', 'spread_bps',
        'depth_imbalance', 'best_bid_size', 'best_ask_size',
        'total_bid_depth', 'total_ask_depth',
        
        # Cross-Asset Metrics (MCX)
        'usdinr_sensitivity', 'usdinr_correlation', 'usdinr_theoretical_price', 'usdinr_basis',
        
        # Market Regime Indicators
        'buy_pressure', 'vix_level', 'volatility_regime',
    ]
```

#### Step 3: Preserve Crawler Fields
```python
def _preserve_crawler_fields(self, tick_data, cleaned):
    """Preserve ALL 184-byte tick data fields from Zerodha WebSocket"""
    # Preserves ALL fields including:
    # - Core packet fields (instrument_token, last_price, volume, OHLC)
    # - Market depth fields
    # - Volume calculations (bucket_incremental_volume, volume_ratio)
    # - IV and Greeks (delta, gamma, theta, vega, rho, iv, implied_volatility)
    # - Option metadata (dte_years, trading_dte, expiry_series, option_price, underlying_price, strike_price)
    # - ALL remaining fields from tick_data
```

#### Step 4: Hydrate Missing Indicators
```python
def _hydrate_missing_indicator_fields(self, symbol: str, source_tick: dict, cleaned: dict):
    """Recover crawler-computed indicator fields (greeks, volume ratio) if they were dropped."""
    # First tries source_tick, then Redis fallback
    # Ensures no computed data is lost
```

### Result
‚úÖ **ALL computed data is preserved and sent downstream:**
- Greeks (classical + advanced)
- Volume calculations (volume_ratio, bucket_incremental_volume)
- Technical indicators (RSI, MACD, EMAs, ATR, VWAP, etc.)
- Microstructure metrics (microprice, order flow imbalance, spread, depth)
- Option metadata (IV, DTE, strike, underlying price)
- Cross-asset metrics (USDINR sensitivity, correlation)
- Market regime indicators (VIX level, volatility regime)

---

## 6. Recommended Fix

### Option 1: Normalize Symbol in Tick Data (Recommended)
**Ensure symbol field in tick data matches normalized key format:**

```python
def _store_tick_data(self, tick: Dict[str, Any]):
    """Store tick data in Redis using unified standards"""
    symbol = tick.get('symbol')
    if not symbol:
        return
    
    # ‚úÖ FIX: Normalize symbol IN TICK DATA to match normalized key
    from shared_core.redis_clients.redis_key_standards import RedisKeyStandards
    canonical_symbol = RedisKeyStandards.canonical_symbol(symbol)
    
    # Update tick data with canonical symbol (ensures consistency)
    tick['symbol'] = canonical_symbol
    tick['tradingsymbol'] = canonical_symbol
    
    # Normalize tick data (field names)
    normalized = normalize_redis_tick_data(tick)
    
    # Store tick (key builder normalizes internally, but we've already normalized tick data)
    key = self.key_builder.live_ticks_latest(canonical_symbol)  # ‚úÖ Key normalized
    self.redis_client.hset(key, mapping=normalized)  # ‚úÖ Tick data also has normalized symbol
    
    # Store indicators (storage normalizes internally)
    indicators = self._extract_indicators(tick)
    if indicators:
        self.storage.store_indicators(canonical_symbol, indicators)  # ‚úÖ Normalized
    
    # Store Greeks (storage normalizes internally)
    greeks = {k: tick[k] for k in greek_fields if k in tick}
    if greeks:
        self.storage.store_indicators(canonical_symbol, greeks, category="greeks")  # ‚úÖ Normalized
```

**Note:** The key builder and storage already normalize symbols internally, but normalizing the symbol in tick data ensures consistency between the key format and the data format.

### Option 2: Remove Normalization from Data Pipeline (Not Recommended)
Remove normalization from data_pipeline since data should already be normalized. However, this doesn't fix the root cause.

---

## 6. Additional Findings

### Optimized Stream Processor
**Location:** `intraday_scanner/optimized_stream_processor.py`

```python
# ‚úÖ FIXED: Get canonical symbol for consistent storage/retrieval
from shared_core.redis_clients.redis_key_standards import RedisKeyStandards
canonical_symbol = RedisKeyStandards.canonical_symbol(symbol)  # ‚úÖ Normalizes
```

**Status:** ‚úÖ Correctly normalizes symbols

### Calculations Module
**Location:** `intraday_scanner/calculations.py`

```python
# ‚úÖ CRITICAL FIX: Check symbol with normalization (handle exchange prefixes)
tick_symbol = tick.get('symbol') or tick.get('tradingsymbol', '')
# Normalize both symbols for comparison (strip exchange prefixes)
normalized_tick_symbol = tick_symbol.upper().replace('NFO:', '').replace('NSE:', '')  # ‚ö†Ô∏è Manual normalization
```

**Status:** ‚ö†Ô∏è Uses manual normalization instead of `RedisKeyStandards.canonical_symbol()`

---

## 7. Summary of Issues

| Component | Symbol Format | Issue |
|-----------|--------------|-------|
| **Websocket Parser - Redis Keys** | Canonical (normalized) | ‚úÖ Key builder normalizes internally |
| **Websocket Parser - Tick Data** | May be raw | ‚ö†Ô∏è Symbol field in tick data might not match normalized key |
| **Data Pipeline** | Canonical (normalized) | ‚úÖ Normalizes symbol field in tick data |
| **Optimized Stream Processor** | Canonical (normalized) | ‚úÖ Correctly normalizes |
| **Calculations Module** | Manual normalization | ‚ö†Ô∏è Should use `RedisKeyStandards.canonical_symbol()` |

---

## 8. Action Items

1. **VERIFIED:** ‚úÖ Key builder methods normalize symbols internally
   - `live_ticks_latest()` normalizes via `RedisKeyStandards.canonical_symbol()`
   - `store_indicators()` normalizes via `RedisKeyStandards.canonical_symbol()`
   - **Status:** Working correctly

2. **VERIFIED:** ‚úÖ Data pipeline preserves ALL computed fields
   - `_preserve_all_original_data()` preserves every field
   - `_smart_merge_redis_data()` fills gaps from Redis
   - `_preserve_crawler_fields()` preserves crawler-calculated fields
   - `_hydrate_missing_indicator_fields()` recovers missing indicators
   - **Status:** Comprehensive preservation implemented

3. **OPTIONAL:** Normalize symbol in tick data for consistency
   - File: `zerodha/crawlers/intraday_websocket_parser.py`
   - Method: `_store_tick_data()`
   - Change: Normalize symbol field in tick data to match normalized key format
   - **Note:** This is optional since data_pipeline already normalizes it

4. **IMPORTANT:** Fix calculations module to use centralized normalization
   - File: `intraday_scanner/calculations.py`
   - Method: `_bootstrap_from_redis_history()`
   - Change: Replace manual normalization with `RedisKeyStandards.canonical_symbol()`

---

## 9. Testing Checklist

Current Status:
- [x] ‚úÖ Key builder normalizes symbols internally
- [x] ‚úÖ Data pipeline preserves ALL computed fields
- [x] ‚úÖ Data pipeline normalizes symbols before processing
- [x] ‚úÖ All consumers receive normalized symbols
- [ ] ‚ö†Ô∏è Symbol field in tick data may be raw (optional fix)

Recommended Tests:
- [ ] Verify all computed fields (Greeks, indicators, volume) are preserved through data_pipeline
- [ ] Verify no data loss occurs during cleaning
- [ ] Test with various symbol formats (NIFTY, NIFTY25NOV26400CE, NFO:NIFTY, etc.)
- [ ] Verify downstream consumers receive all computed fields

---

## 10. Summary

### ‚úÖ What's Working Correctly

1. **Key Builder Normalization:** All key builder methods normalize symbols internally using `RedisKeyStandards.canonical_symbol()`
2. **Data Pipeline Preservation:** Comprehensive preservation of ALL computed fields:
   - `_preserve_all_original_data()` - Preserves every field from original tick
   - `_smart_merge_redis_data()` - Fills gaps from Redis without overwriting fresh data
   - `_preserve_crawler_fields()` - Preserves crawler-calculated fields (Greeks, IV, volume, etc.)
   - `_hydrate_missing_indicator_fields()` - Recovers missing indicators from Redis
3. **Symbol Normalization:** Data pipeline normalizes symbols before processing, ensuring consistency

### ‚ö†Ô∏è Optional Improvements

1. **Symbol in Tick Data:** The symbol field in stored tick data may be raw, but this is handled by data_pipeline normalization
2. **Manual Normalization:** Some modules use manual normalization instead of `RedisKeyStandards.canonical_symbol()`

### üéØ Key Takeaway

**The system is designed correctly:**
- Websocket parser stores with normalized keys (via key builder)
- Data pipeline reads, cleans, normalizes symbols, and preserves ALL computed fields
- Downstream consumers receive clean, normalized data with all fields preserved

---

## 11. Related Files

- `zerodha/crawlers/intraday_websocket_parser.py` - Source of truth (needs fix)
- `intraday_scanner/data_pipeline.py` - Downstream consumer (correctly normalizes)
- `intraday_scanner/optimized_stream_processor.py` - Downstream consumer (correctly normalizes)
- `intraday_scanner/calculations.py` - Uses manual normalization (needs fix)
- `shared_core/redis_clients/redis_key_standards.py` - Centralized normalization logic

